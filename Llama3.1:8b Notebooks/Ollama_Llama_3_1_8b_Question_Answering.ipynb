{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "This notebook demonstrates the capabilities of Ollama's Llama 3.1:8b model in answering questions users may have."
      ],
      "metadata": {
        "id": "dm7bHqXSlOXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation\n",
        "\n",
        "<p align=\"justify\">\n",
        "Executes and runs the ollama_install.sh installing ollama on your machine.\n",
        "</p>"
      ],
      "metadata": {
        "id": "6IZ9UFZ3gMXR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6YjrDfpdR-_",
        "outputId": "90f2c363-1599-467a-fc13-3dea8e74a3e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing Ollama on your environment\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "############################################################################################# 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ],
      "source": [
        "!chmod +x /content/ollama_install.sh\n",
        "!/content/ollama_install.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Ollama Service\n",
        "\n",
        "To run the Ollama service in the background,  this method down below allows the Ollama service to stay active while the main program continues executing other tasks."
      ],
      "metadata": {
        "id": "tXN_EK95iy-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run '/content/ollama_thread.py'"
      ],
      "metadata": {
        "id": "8U46w_7IicXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading Ollama's Llama 3.1:8b Model\n",
        "\n",
        "The command down below downloads the Llama 3.1:8b model from Ollama's repository to our Jupyter Notebook's environment."
      ],
      "metadata": {
        "id": "bXQcOikRi8Gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull llama3.1:8b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2akgwMOiyK6",
        "outputId": "11b00539-617c-441c-c610-b69149dfd7a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 667b0c1932bc... 100% ▕▏ 4.9 GB                         \n",
            "pulling 948af2743fc7... 100% ▕▏ 1.5 KB                         \n",
            "pulling 0ba8f0e314b4... 100% ▕▏  12 KB                         \n",
            "pulling 56bb8bd477a5... 100% ▕▏   96 B                         \n",
            "pulling 455f34728c9b... 100% ▕▏  487 B                         \n",
            "verifying sha256 digest \n",
            "writing manifest \n",
            "success \u001b[?25h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading LangChain Ollama\n",
        "\n",
        "Installs LangChain Ollama's integration package, which allows us to use Ollama models within the LangChain framework."
      ],
      "metadata": {
        "id": "wYj-FJHsjLLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-ollama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NajOv0NpjMKV",
        "outputId": "e130c752-9965-4b9e-ab0e-d1fac8deda17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-ollama\n",
            "  Downloading langchain_ollama-0.2.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.20 in /usr/local/lib/python3.10/dist-packages (from langchain-ollama) (0.3.21)\n",
            "Collecting ollama<1,>=0.3.0 (from langchain-ollama)\n",
            "  Downloading ollama-0.4.4-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.20->langchain-ollama) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.20->langchain-ollama) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.20->langchain-ollama) (0.1.147)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.20->langchain-ollama) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.20->langchain-ollama) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.20->langchain-ollama) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.20->langchain-ollama) (4.12.2)\n",
            "Collecting httpx<0.28.0,>=0.27.0 (from ollama<1,>=0.3.0->langchain-ollama)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (3.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (1.2.2)\n",
            "Downloading langchain_ollama-0.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading ollama-0.4.4-py3-none-any.whl (13 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: httpx, ollama, langchain-ollama\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.0\n",
            "    Uninstalling httpx-0.28.0:\n",
            "      Successfully uninstalled httpx-0.28.0\n",
            "Successfully installed httpx-0.27.2 langchain-ollama-0.2.1 ollama-0.4.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "Imports for our notebook."
      ],
      "metadata": {
        "id": "TJeXkvmejWxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ollama\n",
        "from IPython.display import display, Markdown"
      ],
      "metadata": {
        "id": "jd0-Tb21jWO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing Questions\n",
        "\n",
        "The following method below enables Ollama's Llama 3.1:8b to process and answer users' questions."
      ],
      "metadata": {
        "id": "yFW8LTYSjpqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_question(question, model='llama3.1:8b'):\n",
        "  #Question represents the user's inputted question\n",
        "\n",
        "  # Prepare message for Ollama\n",
        "  messages = [\n",
        "      {\n",
        "            'role': 'user',\n",
        "            'content': f'{question}'\n",
        "        }\n",
        "  ]\n",
        "  response = ollama.chat(model=model, messages=messages)\n",
        "  return response['message']['content']"
      ],
      "metadata": {
        "id": "0bxQ2uk8kTx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question Examples"
      ],
      "metadata": {
        "id": "ZK6SheqlkWMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(process_question(\"What is 909 * 860?\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "FEkCOqcbkZRu",
        "outputId": "77f9a39f-c650-4096-a00a-35def1afe54b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "909 × 860 = 782,890."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(process_question(\"Who are some influential figures in AI research?\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "kYQRbLXZkdKh",
        "outputId": "1b5fa3af-9258-4e68-e584-7b23d02979ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "There are many influential figures in the field of Artificial Intelligence (AI) research. Here are some of the most notable ones:\n\n**Early Pioneers**\n\n1. **Alan Turing**: Considered the father of computer science and AI, Turing proposed the Turing Test to measure a machine's ability to exhibit intelligent behavior.\n2. **Marvin Minsky**: A pioneer in neural networks and cognitive psychology, Minsky developed the first neural network model, SNARC (Self-Organizing Neural Analog Computer).\n3. **John McCarthy**: Coined the term \"Artificial Intelligence\" in 1956 and organized the 1956 Dartmouth Summer Research Project on Artificial Intelligence.\n\n**Machine Learning**\n\n1. **David Rumelhart**: Developed the backpropagation algorithm for training neural networks, a crucial component of deep learning.\n2. **Yann LeCun**: Led the development of convolutional neural networks (CNNs) and is a pioneer in deep learning research.\n3. **Geoffrey Hinton**: Known as the \"Godfather of Deep Learning,\" Hinton developed the backpropagation algorithm and was a key figure in popularizing deep learning.\n\n**Computer Vision**\n\n1. **Yoshua Bengio**: Developed the concept of long short-term memory (LSTM) networks, which are widely used in image recognition tasks.\n2. **Demis Hassabis**: Co-founded DeepMind and made significant contributions to the development of AlphaGo, a computer program that defeated a human world champion in Go.\n\n**Natural Language Processing**\n\n1. **Noam Chomsky**: Developed the theory of generative grammar, which laid the foundation for modern NLP.\n2. **Christopher Manning**: Known as one of the most influential researchers in NLP, Manning has made significant contributions to machine translation and text analysis.\n\n**Expert Systems and Knowledge Representation**\n\n1. **John McDermott**: Developed the MYCIN expert system, a pioneering application of AI that demonstrated the potential for AI to aid medical diagnosis.\n2. **Ray Kurzweil**: Known for his work on natural language processing, Kurzweil developed a computer program that could compose music and poetry.\n\n**Other Notable Researchers**\n\n1. **Andrew Ng**: Co-founded Google Brain and made significant contributions to the development of deep learning techniques for image recognition.\n2. **Fei-Fei Li**: Director of the Stanford Artificial Intelligence Lab (SAIL) and a pioneer in computer vision and AI research.\n3. **Demis Hassabis' colleague, Shane Legg**: A leading researcher at DeepMind, known for his work on multi-agent reinforcement learning.\n\nThese individuals have made significant contributions to various areas of AI research, shaping the field into what it is today."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(process_question(\"What were the main causes of the fall of the Roman Empire?\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "HFSKsWijk55_",
        "outputId": "43326d9e-381f-4935-fd71-8804f151dc5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The fall of the Roman Empire is a complex and multifaceted topic that has been debated by historians for centuries. While there is no consensus on a single cause, several factors contributed to its decline and eventual collapse in 476 CE (Western Rome) and 1453 CE (Eastern or Byzantine Rome). Here are some of the main causes:\n\n**Internal Factors:**\n\n1. **Corruption and Mismanagement**: As the empire grew, corruption and mismanagement became widespread among officials. Emperors often relied on their personal connections rather than merit to fill key positions.\n2. **Military Overextension**: The Roman Empire's extensive military campaigns and extensive borders drained its resources and created significant burdens for the economy.\n3. **Decline of the Legions**: As the empire expanded, the quality of soldiers decreased. Many recruits came from barbarian tribes, leading to a loss of Roman culture and values among the military.\n4. **Economic Strains**: The burden of maintaining a vast empire led to financial difficulties, inflation, and trade disruptions.\n\n**External Factors:**\n\n1. **Barbarian Invasions**: Germanic tribes like the Goths, Vandals, and Visigoths frequently invaded Roman territories, weakening its defenses.\n2. **Persian Wars**: Prolonged conflicts with the Sassanian Empire (modern-day Iran) strained Rome's resources and led to territorial losses.\n3. **Huns and Other Nomadic Tribes**: The Huns, a nomadic people from Central Asia, launched devastating attacks on Roman territories in Europe.\n\n**Social and Cultural Factors:**\n\n1. **Decline of the Roman Family Structure**: As the empire grew, traditional family structures were disrupted by urbanization, slavery, and social mobility.\n2. **Economic Inequality**: The widening gap between rich and poor led to social unrest and instability.\n3. **Christianity and the Shift from Traditional Values**: Christianity's influence on Roman society challenged traditional values and created a rift between old and new ways of living.\n\n**Key Events:**\n\n1. **The Year of the Five Emperors (193 CE)**: A succession crisis led by rival claimants to the throne weakened Rome's central authority.\n2. **The Fall of Dacia (271-274 CE)**: The loss of the province of Dacia (modern-day Romania) marked a significant decline in Roman power and influence.\n3. **The Battle of Adrianople (378 CE)**: A decisive defeat at the hands of the Goths led to widespread panic and further weakened Rome's defenses.\n\nWhile these factors contributed to the fall of the Roman Empire, it is essential to note that the process was gradual and involved multiple interacting causes over several centuries."
          },
          "metadata": {}
        }
      ]
    }
  ]
}
